{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Remove axis according to 'valid_axis' list\n",
    "def remove_axis(skeleton_sample):\n",
    "    result, valid_axis = [], [1, 2, 3, 4, 5, 6, 7, 8, 9, 13, 14, 15, 16, 17, 18, 22, 23, 24, 43, 44, 45, 46, 47, 48]\n",
    "\n",
    "    for index in range(skeleton_sample.shape[0]):\n",
    "        result.append(skeleton_sample[index,:]) if index + 1 in valid_axis else None\n",
    "    \n",
    "    result = np.array(result)\n",
    "    return result\n",
    "\n",
    "def interpolate(skeleton_sample, finger_sample):\n",
    "    SKELETON_DATA_LENGTH = skeleton_sample.shape[1]\n",
    "    FINGER_DATA_LENGTH = finger_sample.shape[1]\n",
    "    ratio = (FINGER_DATA_LENGTH - 1) / (SKELETON_DATA_LENGTH - 1)\n",
    "    interpolate_result = []\n",
    "    \n",
    "    # Procedure check the element's value is '-10' in python file and interpolate it using mean value\n",
    "    for line in range(skeleton_sample.shape[0]):\n",
    "        float_line = skeleton_sample[line,:] # To handle, convert string list \"line\" to \"float\" list\n",
    "        invalid_loc = [i for i, x in enumerate(float_line) if x == -10] # Extract the location of element which is value -10\n",
    "        # Interpolate \"p\" point with \"p1\" and \"p2\" point, where the order is p1 << p << p2\n",
    "        for p_index in invalid_loc:\n",
    "            p1_index = max([index for index, value in enumerate(float_line) if value != -10 and index < p_index])\n",
    "            p2_index = min([index for index, value in enumerate(float_line) if value != -10 and index > p_index])\n",
    "            p_value = float_line[p1_index] + (float_line[p2_index] - float_line[p1_index]) * (p_index - p1_index) / (p2_index - p1_index) # Linear interpolation method (https://en.wikipedia.org/wiki/Linear_interpolation)\n",
    "            float_line[p_index] = round(p_value, 2)\n",
    "\n",
    "        interpolate_result.append(float_line)\n",
    "\n",
    "    final_result = [[0 for i in range(FINGER_DATA_LENGTH)] for j in range(len(interpolate_result))] # Make 2D array, same column with 'MATLAB' & same row with 'PYTHON'\n",
    "    valid_loc = []\n",
    "\n",
    "    # Filling the value in 'final_result' list with some stride\n",
    "    for row_index, row in enumerate(interpolate_result):\n",
    "        count = 0\n",
    "\n",
    "        # The values of \"interpolation_result\" are inserted in final result and that locations are inserted in valid_loc\n",
    "        while count * ratio < FINGER_DATA_LENGTH:\n",
    "            valid_loc.append(round(count * ratio)) if row_index == 0 else None\n",
    "            final_result[row_index][round(count * ratio)] = row[count]\n",
    "            count += 1\n",
    "    \n",
    "    # Interpolate the element of 'final_result' list which value is 0\n",
    "    for row_index, row in enumerate(final_result):\n",
    "        # p1, p2 points are valid pixel and the pixels between them are invalid\n",
    "        # Process interpolation invalid pixel using p1 and p2 value\n",
    "        for x in range(len(valid_loc) - 1):\n",
    "            p1_index, p2_index = valid_loc[x], valid_loc[x + 1]\n",
    "            p1_value, p2_value = final_result[row_index][p1_index], final_result[row_index][p2_index]\n",
    "            dis = (p2_value - p1_value) / (p2_index - p1_index)\n",
    "\n",
    "            for i in range(p1_index + 1, p2_index):\n",
    "                final_result[row_index][i] = round(final_result[row_index][i - 1] + dis, 4)\n",
    "\n",
    "    return np.array(final_result)\n",
    "\n",
    "def location_generator(windowed_skeleton_sample):\n",
    "    nose = windowed_skeleton_sample[:,:3] # joint index = 1 (starting with 1)\n",
    "    torso = windowed_skeleton_sample[:,3:6] # joint index = 2\n",
    "    right_shoulder = windowed_skeleton_sample[:,6:9] # joint index = 3\n",
    "    right_hand = windowed_skeleton_sample[:,9:12] # joint index = 5\n",
    "    left_shoulder = windowed_skeleton_sample[:,12:15] # joint index = 6\n",
    "    left_hand = windowed_skeleton_sample[:,15:18] # joint index = 8\n",
    "    right_eye = windowed_skeleton_sample[:,18:21] # joint index = 15\n",
    "    left_eye = windowed_skeleton_sample[:,21:24] # joint index = 16\n",
    "    \n",
    "    LL = np.hstack((left_hand-nose, left_hand-torso, left_hand-right_shoulder, left_hand-left_shoulder))\n",
    "    LR = np.hstack((right_hand-nose, right_hand-torso, right_hand-right_shoulder, right_hand-left_shoulder))\n",
    "    \n",
    "    return LL, LR\n",
    "\n",
    "def movement_generator(windowed_skeleton_sample):\n",
    "    right_hand = windowed_skeleton_sample[:,9:12] # joint index = 5\n",
    "    left_hand = windowed_skeleton_sample[:,15:18] # joint index = 8\n",
    "    \n",
    "    left_mean_pos = np.mean(left_hand, axis=0)\n",
    "    right_mean_pos = np.mean(right_hand, axis=0)\n",
    "    \n",
    "    for i in range(left_hand.shape[0]):\n",
    "        left_dist = np.linalg.norm(left_hand[i,:]-left_mean_pos)\n",
    "        right_dist = np.linalg.norm(right_hand[i,:]-right_mean_pos)\n",
    "        \n",
    "        if i==0:\n",
    "            left_shape = left_dist\n",
    "            right_shape = right_dist\n",
    "        else:\n",
    "            left_shape = np.hstack((left_shape,left_dist))\n",
    "            right_shape = np.hstack((right_shape,right_dist))\n",
    "    \n",
    "    left_direction = left_hand[-1,:] - left_hand[0,:]\n",
    "    right_direction = right_hand[-1,:] - right_hand[0,:]\n",
    "    \n",
    "    ML = np.hstack((left_shape, left_direction))\n",
    "    MR = np.hstack((right_shape, right_direction))\n",
    "    \n",
    "    return ML, MR\n",
    "\n",
    "def handshape_generator(windowed_finger_sample):\n",
    "    left_hand = windowed_finger_sample[:,:10]\n",
    "    right_hand = windowed_finger_sample[:,10:]\n",
    "    \n",
    "    return left_hand, right_hand\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    window_size = 25\n",
    "    window_stride = 25\n",
    "    \n",
    "    finger_raw = r'D:\\\\MinHyuk\\\\Hand Sign Recognition\\\\2021_SLT_prj\\\\DATA\\\\finger_raw'\n",
    "    skeleton_raw = r'D:\\\\MinHyuk\\\\Hand Sign Recognition\\\\2021_SLT_prj\\\\DATA\\\\skeleton_raw'\n",
    "    HSL_path = 'D:\\\\MinHyuk\\\\Hand Sign Recognition\\\\2021_SLT_prj\\\\DATA\\\\feature\\\\HSL'\n",
    "    HSR_path = 'D:\\\\MinHyuk\\\\Hand Sign Recognition\\\\2021_SLT_prj\\\\DATA\\\\feature\\\\HSR'    \n",
    "    LL_path = 'D:\\\\MinHyuk\\\\Hand Sign Recognition\\\\2021_SLT_prj\\\\DATA\\\\feature\\\\LL'\n",
    "    LR_path = 'D:\\\\MinHyuk\\\\Hand Sign Recognition\\\\2021_SLT_prj\\\\DATA\\\\feature\\\\LR'\n",
    "    ML_path = 'D:\\\\MinHyuk\\\\Hand Sign Recognition\\\\2021_SLT_prj\\\\DATA\\\\feature\\\\ML'\n",
    "    MR_path = 'D:\\\\MinHyuk\\\\Hand Sign Recognition\\\\2021_SLT_prj\\\\DATA\\\\feature\\\\MR'    \n",
    "    \n",
    "    # Phoneme dictionary load\n",
    "    HS_path = \"D:\\\\MinHyuk\\\\Hand Sign Recognition\\\\2021_SLT_prj\\\\DATA\\\\phoneme_dict\\\\Handshape\"\n",
    "    HS_dict = np.array(pd.read_csv(HS_path+'\\\\HS_raw.csv',header=None), dtype='float32')\n",
    "    L_path = \"D:\\\\MinHyuk\\\\Hand Sign Recognition\\\\2021_SLT_prj\\\\DATA\\\\phoneme_dict\\\\Location\"\n",
    "    L_dict = np.array(pd.read_csv(L_path+'\\\\L_raw.csv',header=None), dtype='float32')\n",
    "    M_path = \"D:\\\\MinHyuk\\\\Hand Sign Recognition\\\\2021_SLT_prj\\\\DATA\\\\phoneme_dict\\\\Movement\"\n",
    "    M_dict = np.array(pd.read_csv(M_path+'\\\\M_raw.csv',header=None), dtype='float32')\n",
    "    \n",
    "    skeleton_sample_set = []\n",
    "    finger_sample_set = []\n",
    "    for skeleton_sample_name, finger_sample_name in zip(glob(skeleton_raw+'\\\\*.csv'), glob(finger_raw+'\\\\*.csv')):\n",
    "        finger_sample = np.array(pd.read_csv(finger_sample_name, header=None), dtype='float32')\n",
    "        if not finger_sample_set:\n",
    "            finger_sample_set = [finger_sample]\n",
    "        else:\n",
    "            finger_sample_set.append(finger_sample)\n",
    "        \n",
    "        skeleton_sample = np.array(pd.read_csv(skeleton_sample_name, header=None), dtype='float32')\n",
    "        skeleton_sample = remove_axis(skeleton_sample) # 불필요한 skeletal point 제거\n",
    "        skeleton_sample = interpolate(skeleton_sample, finger_sample)\n",
    "        if not skeleton_sample_set:\n",
    "            skeleton_sample_set = [skeleton_sample]\n",
    "        else:\n",
    "            skeleton_sample_set.append(skeleton_sample)\n",
    "    \n",
    "    # Export preprocessed handshape feature sequences\n",
    "    # Feature extraction, standardization, windowing, export data (순서 중요!)\n",
    "    HSL_sample_set = [None] * len(finger_sample_set)\n",
    "    HSR_sample_set = [None] * len(finger_sample_set)\n",
    "    for i, finger_sample in enumerate(finger_sample_set):\n",
    "        HSL_sample_set[i], HSR_sample_set[i] = handshape_generator(np.transpose(finger_sample)) # Feature extraction\n",
    "    \n",
    "    HS_serial_connect = [] # 왼손, 오른손 합쳐서 mean/std 계산\n",
    "    i=0\n",
    "    for HSL_sample, HSR_sample in zip(HSL_sample_set, HSR_sample_set):\n",
    "        if i==0:\n",
    "            HS_serial_connect = HSL_sample\n",
    "            HS_serial_connect = np.vstack((HS_serial_connect, HSR_sample))\n",
    "                        \n",
    "        else:\n",
    "            HS_serial_connect = np.vstack((HS_serial_connect, HSL_sample))\n",
    "            HS_serial_connect = np.vstack((HS_serial_connect, HSR_sample))\n",
    "        i=i+1\n",
    "        \n",
    "    HS_mean = np.mean(HS_serial_connect, axis=0)\n",
    "    HS_std = np.std(HS_serial_connect, axis=0)\n",
    "    \n",
    "    for i, HSL_sample in enumerate(HSL_sample_set): # Standardization\n",
    "        HSL_sample_set[i] = (HSL_sample - HS_mean)/HS_std\n",
    "    \n",
    "    for i, HSR_sample in enumerate(HSR_sample_set):\n",
    "        HSR_sample_set[i] = (HSR_sample - HS_mean)/HS_std\n",
    "    \n",
    "    # Export standardized handshape phoneme\n",
    "    HS_dict = (HS_dict - HS_mean)/HS_std\n",
    "    \n",
    "    HS_dict_for_save = pd.DataFrame(HS_dict)\n",
    "    filename = HS_path + '\\\\HS_normalized.csv'\n",
    "    HS_dict_for_save.to_csv(filename, mode='w', header=False, index=False)\n",
    "    \n",
    "    # Windowing\n",
    "    for HSL_sample, finger_sample_name in zip(HSL_sample_set, os.listdir(finger_raw)[1:]):\n",
    "        chop_sample = tf.keras.utils.timeseries_dataset_from_array(HSL_sample, targets=None, batch_size = 1, sequence_length = window_size, sequence_stride= window_stride, shuffle=False)\n",
    "        windowed_set = list(chop_sample.as_numpy_iterator()) # list 타입, 각 element는 array, 각 element의 shape = (window_length,sensor)\n",
    "        for i in range(len(windowed_set)):\n",
    "            windowed_HSL_sample = windowed_set[i]\n",
    "            windowed_HSL_sample = windowed_HSL_sample[0,:,:]                                      \n",
    "            HSL_each_window = np.vstack((windowed_HSL_sample, 10000*np.ones((1,windowed_HSL_sample.shape[1]))))\n",
    "            \n",
    "            if i==0:\n",
    "                HSL_sample_final = HSL_each_window\n",
    "            else:\n",
    "                HSL_sample_final = np.vstack((HSL_sample_final, HSL_each_window))\n",
    "    \n",
    "        HSL_sample_for_save = pd.DataFrame(HSL_sample_final)\n",
    "        filename = HSL_path + '\\\\[HSL]' + finger_sample_name[8:]\n",
    "        HSL_sample_for_save.to_csv(filename, mode='w', header=False, index=False) # Export data\n",
    "                                                                      \n",
    "    for HSR_sample, finger_sample_name in zip(HSR_sample_set, os.listdir(finger_raw)[1:]):\n",
    "        chop_sample = tf.keras.utils.timeseries_dataset_from_array(HSR_sample, targets=None, batch_size = 1, sequence_length = window_size, sequence_stride= window_stride, shuffle=False)\n",
    "        windowed_set = list(chop_sample.as_numpy_iterator()) # list 타입, 각 element는 array, 각 element의 shape = (window_length,sensor)\n",
    "        for i in range(len(windowed_set)):\n",
    "            windowed_HSR_sample = windowed_set[i]\n",
    "            windowed_HSR_sample = windowed_HSR_sample[0,:,:]                                      \n",
    "            HSR_each_window = np.vstack((windowed_HSR_sample, 10000*np.ones((1,windowed_HSR_sample.shape[1]))))\n",
    "\n",
    "            if i==0:\n",
    "                HSR_sample_final = HSR_each_window\n",
    "            else:\n",
    "                HSR_sample_final = np.vstack((HSR_sample_final, HSR_each_window))\n",
    "                \n",
    "        HSR_sample_for_save = pd.DataFrame(HSR_sample_final)\n",
    "        filename = HSR_path + '\\\\[HSR]' + finger_sample_name[8:]\n",
    "        HSR_sample_for_save.to_csv(filename, mode='w', header=False, index=False) # Export data\n",
    "        \n",
    "    # Export preprocessed movement feature sequences\n",
    "    # Windowing, feature extraction, standardization, export data (순서 중요!)\n",
    "    ML_serial_connect = [] # list 타입, 각 element는 timestep방향으로 stack된 movement sample, (timestep,movement feature)\n",
    "    MR_serial_connect = []\n",
    "    for skeleton_sample in skeleton_sample_set: # Windowing\n",
    "        ML_sample_connect = []\n",
    "        MR_sample_connect = []\n",
    "        chop_sample = tf.keras.utils.timeseries_dataset_from_array(np.transpose(skeleton_sample), targets=None, batch_size = 1, sequence_length = window_size, sequence_stride= window_stride, shuffle=False)\n",
    "        windowed_set = list(chop_sample.as_numpy_iterator()) # list 타입, 각 element는 array, 각 element의 shape = (window_length,sensor)\n",
    "        for i in range(len(windowed_set)):\n",
    "            windowed_skeleton_sample = windowed_set[i]\n",
    "            windowed_skeleton_sample = windowed_skeleton_sample[0,:,:]\n",
    "            \n",
    "            ML_each_window, MR_each_window = movement_generator(windowed_skeleton_sample) # Feature extraction\n",
    "            \n",
    "            if i==0:\n",
    "                ML_sample_connect = ML_each_window\n",
    "            else:\n",
    "                ML_sample_connect = np.vstack((ML_sample_connect,ML_each_window))\n",
    "            \n",
    "            if i==0:\n",
    "                MR_sample_connect = MR_each_window\n",
    "            else:\n",
    "                MR_sample_connect = np.vstack((MR_sample_connect,MR_each_window))\n",
    "                \n",
    "        if not ML_serial_connect:\n",
    "            ML_serial_connect = [ML_sample_connect]\n",
    "        else:\n",
    "            ML_serial_connect.append(ML_sample_connect)\n",
    "        if not MR_serial_connect:\n",
    "            MR_serial_connect = [MR_sample_connect]\n",
    "        else:\n",
    "            MR_serial_connect.append(MR_sample_connect)\n",
    "    \n",
    "    M_total_connect = ML_serial_connect + MR_serial_connect # 왼손, 오른손 합쳐서 mean/std 계산\n",
    "    M_total_serial_connect = []\n",
    "    for i, M_total_sample in enumerate(M_total_connect):\n",
    "        if i==0:\n",
    "            M_total_serial_connect = M_total_sample\n",
    "        else:\n",
    "            M_total_serial_connect = np.vstack((M_total_serial_connect, M_total_sample))\n",
    "    M_mean = np.mean(M_total_serial_connect, axis=0)\n",
    "    M_std = np.std(M_total_serial_connect, axis=0)\n",
    "    \n",
    "    # Export standardized movement phoneme\n",
    "    M_dict = (M_dict - M_mean)/M_std\n",
    "    \n",
    "    M_dict_for_save = pd.DataFrame(M_dict)\n",
    "    filename = M_path + '\\\\M_normalized.csv'\n",
    "    M_dict_for_save.to_csv(filename, mode='w', header=False, index=False)\n",
    "    \n",
    "    for i, ML_sample in enumerate(ML_serial_connect): # Standardization\n",
    "        ML_serial_connect[i] = (ML_sample - M_mean)/M_std\n",
    "    for i, MR_sample in enumerate(MR_serial_connect):\n",
    "        MR_serial_connect[i] = (MR_sample - M_mean)/M_std\n",
    "    \n",
    "    for ML_sample_connect, skeleton_sample_name in zip(ML_serial_connect, os.listdir(skeleton_raw)[1:]):\n",
    "        ML_sample = []\n",
    "        for i in range(ML_sample_connect.shape[0]):\n",
    "            ML_each_window = ML_sample_connect[i,:]\n",
    "            ML_each_window = np.vstack((ML_each_window, 10000*np.ones((1,len(ML_each_window)))))\n",
    "            if i==0:\n",
    "                ML_sample = ML_each_window\n",
    "            else:\n",
    "                ML_sample = np.vstack((ML_sample, ML_each_window))       \n",
    "        ML_sample_for_save = pd.DataFrame(ML_sample)\n",
    "        filename = ML_path + '\\\\[ML]' + skeleton_sample_name[8:]\n",
    "        ML_sample_for_save.to_csv(filename, mode='w', header=False, index=False) # Export data\n",
    "    \n",
    "    for MR_sample_connect, skeleton_sample_name in zip(MR_serial_connect, os.listdir(skeleton_raw)[1:]):\n",
    "        MR_sample = []\n",
    "        for i in range(MR_sample_connect.shape[0]):\n",
    "            MR_each_window = MR_sample_connect[i,:]\n",
    "            MR_each_window = np.vstack((MR_each_window, 10000*np.ones((1,len(MR_each_window)))))\n",
    "            if i==0:\n",
    "                MR_sample = MR_each_window\n",
    "            else:\n",
    "                MR_sample = np.vstack((MR_sample, MR_each_window))       \n",
    "        MR_sample_for_save = pd.DataFrame(MR_sample)\n",
    "        filename = MR_path + '\\\\[MR]' + skeleton_sample_name[8:]\n",
    "        MR_sample_for_save.to_csv(filename, mode='w', header=False, index=False) # Export data\n",
    "\n",
    "    # Export preprocessed location feature sequences\n",
    "    # Feature extraction, standardization, windowing, export data (순서 중요!)\n",
    "    LL_sample_set = [None] * len(skeleton_sample_set)\n",
    "    LR_sample_set = [None] * len(skeleton_sample_set)\n",
    "    for i, skeleton_sample in enumerate(skeleton_sample_set):\n",
    "        LL_sample_set[i],LR_sample_set[i] = location_generator(np.transpose(skeleton_sample)) # Feature extraction\n",
    "    \n",
    "    L_serial_connect = [] # 왼손, 오른손 합쳐서 mean/std 계산\n",
    "    i=0\n",
    "    for LL_sample, LR_sample in zip(LL_sample_set, LR_sample_set):\n",
    "        if i==0:\n",
    "            L_serial_connect = LL_sample\n",
    "            L_serial_connect = np.vstack((L_serial_connect, LR_sample))\n",
    "                        \n",
    "        else:\n",
    "            L_serial_connect = np.vstack((L_serial_connect, LL_sample))\n",
    "            L_serial_connect = np.vstack((L_serial_connect, LR_sample))\n",
    "        i=i+1\n",
    "        \n",
    "    L_mean = np.mean(L_serial_connect, axis=0)\n",
    "    L_std = np.std(L_serial_connect, axis=0)\n",
    "\n",
    "    # Export standardized movement phoneme\n",
    "    L_dict = (L_dict - L_mean)/L_std\n",
    "    \n",
    "    L_dict_for_save = pd.DataFrame(L_dict)\n",
    "    filename = L_path + '\\\\L_normalized.csv'\n",
    "    L_dict_for_save.to_csv(filename, mode='w', header=False, index=False)\n",
    "    \n",
    "    for i, LL_sample in enumerate(LL_sample_set): # Standardization\n",
    "        LL_sample_set[i] = (LL_sample - L_mean)/L_std\n",
    "    \n",
    "    for i, LR_sample in enumerate(LR_sample_set):\n",
    "        LR_sample_set[i] = (LR_sample - L_mean)/L_std\n",
    "    \n",
    "    # Windowing\n",
    "    for LL_sample, skeleton_sample_name in zip(LL_sample_set, os.listdir(skeleton_raw)[1:]):\n",
    "        chop_sample = tf.keras.utils.timeseries_dataset_from_array(LL_sample, targets=None, batch_size = 1, sequence_length = window_size, sequence_stride= window_stride, shuffle=False)\n",
    "        windowed_set = list(chop_sample.as_numpy_iterator()) # list 타입, 각 element는 array, 각 element의 shape = (window_length,sensor)\n",
    "        for i in range(len(windowed_set)):\n",
    "            windowed_LL_sample = windowed_set[i]\n",
    "            windowed_LL_sample = windowed_LL_sample[0,:,:]                                      \n",
    "            LL_each_window = np.vstack((windowed_LL_sample, 10000*np.ones((1,windowed_LL_sample.shape[1]))))\n",
    "            \n",
    "            if i==0:\n",
    "                LL_sample_final = LL_each_window\n",
    "            else:\n",
    "                LL_sample_final = np.vstack((LL_sample_final, LL_each_window))\n",
    "    \n",
    "        LL_sample_for_save = pd.DataFrame(LL_sample_final)\n",
    "        filename = LL_path + '\\\\[LL]' + skeleton_sample_name[8:]\n",
    "        LL_sample_for_save.to_csv(filename, mode='w', header=False, index=False) # Export data\n",
    "                                                                      \n",
    "    for LR_sample, skeleton_sample_name in zip(LR_sample_set, os.listdir(skeleton_raw)[1:]):\n",
    "        chop_sample = tf.keras.utils.timeseries_dataset_from_array(LR_sample, targets=None, batch_size = 1, sequence_length = window_size, sequence_stride= window_stride, shuffle=False)\n",
    "        windowed_set = list(chop_sample.as_numpy_iterator()) # list 타입, 각 element는 array, 각 element의 shape = (window_length,sensor)\n",
    "        for i in range(len(windowed_set)):\n",
    "            windowed_LR_sample = windowed_set[i]\n",
    "            windowed_LR_sample = windowed_LR_sample[0,:,:]                                      \n",
    "            LR_each_window = np.vstack((windowed_LR_sample, 10000*np.ones((1,windowed_LR_sample.shape[1]))))\n",
    "\n",
    "            if i==0:\n",
    "                LR_sample_final = LR_each_window\n",
    "            else:\n",
    "                LR_sample_final = np.vstack((LR_sample_final, LR_each_window))\n",
    "                \n",
    "        LR_sample_for_save = pd.DataFrame(LR_sample_final)\n",
    "        filename = LR_path + '\\\\[LR]' + skeleton_sample_name[8:]\n",
    "        LR_sample_for_save.to_csv(filename, mode='w', header=False, index=False) # Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
